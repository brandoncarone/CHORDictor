{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["Xt50qt6nq7Zp","gj-XM32GRfGW"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# CHORDictor"],"metadata":{"id":"CO33EsS8ruxx"}},{"cell_type":"markdown","source":["## Description\n","\n","### Project Scope\n","A Python program that can automatically annotate the jazz chord progressions for a MIDI file. For any ambiguous chords or sections which the program cannot determine an annotation for, the program will flag them and the human user can manually enter the corresponding label to ensure the annotation accuracy.\n","\n","### Data\n","* Jazz Piano MIDI Multitracks\n","* Size: 310 MIDI files\n","* Source: https://bushgrafts.com/midi/"],"metadata":{"id":"d1q_VECbexG8"}},{"cell_type":"markdown","source":["## Member Contributions\n","\n","### Brandon Carone\n","* Initial scope of the project\n","* MIDI data loading and parsing\n","* MIDI Chord Templates - 33 chords in 12 keys\n","* Mapping notes to chords (templates)\n","\n","\n","### Kenny Huang\n","* MIDI data loading, parsing, & visualizing\n","* Selected method of parsing MIDI file (mido over music21)\n","* Converted key format from music21 to librosa\n","* Converted accidentals formatting\n","* Obtained music21's in-build chord-detection algorithm\n","* Helped write some MIDI processing functions\n","\n","### Richa Namballa\n","* Documented code\n","* Wrote helper functions\n","* Quantized MIDI file\n","* Time-aligned MIDI parsing\n","* Converted MIDI to note names\n","* Extracted timestamps of each note\n","* Separated notes into individual beats"],"metadata":{"id":"JMazJLTHe6Ia"}},{"cell_type":"markdown","source":["## Install & Import Libraries"],"metadata":{"id":"eLpX2tbKr3Zk"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"yXRd2AKG-PaJ"},"outputs":[],"source":["!pip install mido\n","!pip install music21"]},{"cell_type":"code","source":["import os\n","import copy\n","import numpy as np\n","import pandas as pd\n","import librosa\n","import mido\n","import re\n","import matplotlib.pyplot as plt\n","from glob import glob\n","from music21 import midi, chord\n","from tqdm import tqdm"],"metadata":{"id":"H5_e7AKjsm32"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Load Data"],"metadata":{"id":"6bGLwjlrsEB_"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive/')"],"metadata":{"id":"DLO6-bVQso_e"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# upload the jazz_midi folder to mir_datasets folder in Drive\n","midi_dir = '/content/drive/MyDrive/mir_datasets/jazz_midi/*.mid'\n","midi_files = []\n","for midi_file in tqdm(glob(midi_dir)):\n","    midi_files.append(midi_file)\n","midi_files.sort()"],"metadata":{"id":"yl8TSKZ4bGPx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Data Preprocessing"],"metadata":{"id":"Ylj3uceWew3V"}},{"cell_type":"markdown","source":["### Helper Functions"],"metadata":{"id":"csz0-j9HYZMA"}},{"cell_type":"code","source":["def quantize_file(midi_file_path, out_path, divisor=8, offsets=True, durations=True):\n","    \"\"\"\n","    Quantize a the inputted MIDI file.\n","    \n","    :param midi_file_path: (str) path to MIDI file to be quantized\n","    :param out_path: (str) path to written quantized MIDI file\n","    :param divisor: (int) the subdivision of a quarter note to quantize to,\n","                    the default value is 8, which corresponds to a 1/32nd note\n","    :param offets: (bool) whether to quantize the note offsets\n","    :param durations: (bool) where to quantize the note durations\n","    \"\"\"\n","    mf = midi.MidiFile()\n","    mf.open(midi_file_path, 'rb')\n","    mf.read()\n","    mf.close()\n","    \n","    s = midi.translate.midiFileToStream(mf)\n","    s.quantize((divisor,),\n","               processOffsets=offsets,\n","               processDurations=durations,\n","               inPlace=True, recurse=True)\n","    \n","    mf_quant = midi.translate.streamToMidiFile(s)\n","    \n","    mf_quant.open(out_path, 'wb')\n","    mf_quant.write()\n","    mf_quant.close()"],"metadata":{"id":"o_wTFqucM6X2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def load_midi(midi_file_path, quantize=True):\n","    \"\"\"\n","    Loads MIDI file using mido.\n","    \n","    :param midi_file_path: (str) path to MIDI file\n","    :param quantize: (bool) whether to quantize the MIDI file\n","    :return: (MidiFile) mido MIDI file object\n","    \"\"\"\n","    if quantize:\n","        # create a temporary MIDI file with quantization\n","        quantize_file(midi_file_path, 'temp.mid')\n","        # load\n","        mid = mido.MidiFile('temp.mid')\n","        print(f'Temporary MIDI file created at {os.path.abspath(\"temp.mid\")}')\n","        # remove temporary file\n","        os.remove('temp.mid')\n","        if os.path.exists('temp.mid'):\n","          print('Unable to remove temporary MIDI file!')\n","    else:\n","        # load\n","        mid = mido.MidiFile(midi_file_path)\n","    return mid"],"metadata":{"id":"PM9bZDmpQFse"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_tempo(mid):\n","    \"\"\"\n","    Determine tempo of the MIDI file.\n","    \n","    :param mid: (MidiFile) mido MIDI file object\n","    :return: (int) tempo in microseconds per beat\n","    \"\"\"\n","    tempo_list = []\n","    for track in mid.tracks:\n","        for msg in track:\n","            if msg.type == 'set_tempo':\n","                 tempo_list.append(msg.tempo)\n","\n","    if len(tempo_list) > 0:\n","        # return the first tempo\n","        return tempo_list[0]\n","    else:\n","        # default tempo from mido\n","        return 500000"],"metadata":{"id":"zy7Ww21cK81u"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_bpm(mid):\n","    \"\"\"\n","    Determine the BPM of the MIDI file\n","    \n","    :param mid: (MidiFile) mido MIDI file object\n","    :return: (int) BPM\n","    \"\"\"\n","    # compute tempo\n","    tempo = get_tempo(mid)\n","    # convert tempo to BPM and round to the nearest integer\n","    bpm = round(mido.tempo2bpm(tempo))\n","    return bpm"],"metadata":{"id":"5VWcSaTwQMcg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_metadata(mid):\n","    \"\"\"\n","    Print metadata from MIDI file\n","    \n","    :param mid: (MidiFile) mido MIDI file object\n","    \"\"\"\n","    for track in mid.tracks:\n","        for msg in track:\n","            if msg.is_meta:\n","                print(msg)\n","    else:\n","        pass"],"metadata":{"id":"0LPQClehK9rq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def remove_octave(note):\n","    \"\"\"\n","    Strips the octave number from a note.\n","    \n","    :param note: (str) note in string form (e.g. 'C5')\n","    :return: (str) note without octave (e.g. 'C')\n","    \"\"\"\n","    # remove digits from the string\n","    chars = [i for i in note if not i.isdigit()]\n","    # rejoin characters\n","    note_without_octave = ''.join(chars)\n","    return note_without_octave"],"metadata":{"id":"3a_odPduT_2t"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def calculate_similarity(list1, list2):\n","    \"\"\"\n","    Computes the proportion of overlap between two lists.\n","\n","    :param list1: (list)\n","    :param list2: (list)\n","    :return: (float) similarity\n","    \"\"\"\n","    denom = max(len(list1), len(list2))  # use the length of the longer list as the denominator\n","    intersect = list(set(list1) & set(list2))  # find the intersection of two sets\n","    numer = len(intersect)\n","    if denom > 0:\n","        sim = numer / denom\n","    else:\n","        # avoids ZeroDivisionError\n","        sim = 0\n","    return sim"],"metadata":{"id":"SzXQN-AumF-e"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Using `mido` to Read MIDI Files"],"metadata":{"id":"dyI3Jbz-RsxA"}},{"cell_type":"code","source":["# adapted from: https://stackoverflow.com/questions/63105201/python-mido-how-to-get-note-starttime-stoptime-track-in-a-list\n","\n","# midi file to array\n","def midi_parser(mid):\n","    \"\"\"\n","    Converts a mido MIDI file into an array of note on/off with timestamps\n","\n","    :param mid: (MidiFile) MIDI file object loaded with mido\n","    :return: (np.ndarray) array of [type, note, time, channel]\n","    \"\"\"\n","    midi_array = []\n","    \n","    # get the tempo in microseconds per beat\n","    tempo = get_tempo(mid)\n","    \n","    # find how many ticks are in a single beat\n","    tpb = mid.ticks_per_beat\n","\n","    # iterate through each track individually\n","    for track in mid.tracks:\n","        track_info = {}\n","        metadata   = {}  # track metadata\n","        note_array = []  # track specific note information\n","        midi_dict  = []  # a list of dictionaries\n","        \n","        # iterate through each message in the track\n","        for msg in track:\n","            # TODO: check whether there are other types of messages\n","            # if (msg.type == 'note_on' or msg.type == 'note_off' or msg.type == 'control_change'):\n","            if not msg.is_meta:\n","                # put all note on/off in midinote as dictionary\n","                midi_dict.append(msg.dict())\n","            elif msg.type == 'track_name':\n","                # save the track name as metadata\n","                metadata['name'] = msg.name\n","            elif msg.type == 'time_signature':\n","                # save the time signature as metadata\n","                metadata['time_signature'] = f'{msg.numerator}/{msg.denominator}'\n","            elif msg.type == 'key_signature':\n","                # save the key as metadata\n","                metadata['key'] = msg.key\n","            else:\n","                pass\n","        \n","        # add the metadata information\n","        track_info['metadata'] = metadata\n","\n","        # change time values from delta to relative time\n","        event_start = 0\n","        for d in midi_dict:\n","            time_in_s = mido.tick2second(d['time'], tpb, tempo)\n","            time = time_in_s + event_start\n","            d['time'] = time\n","            event_start += time_in_s\n","\n","            # make every note_on with 0 velocity note_off\n","            if d['type'] == 'note_on' and d['velocity'] == 0:\n","                d['type'] = 'note_off'\n","\n","            # put note, starttime, stoptime, as nested list in a list\n","            # format is [type, note, time, channel]\n","            event = []\n","            if d['type'] == 'note_on' or d['type'] == 'note_off':\n","                # do not include control change values\n","                event.append(d['type'])\n","                event.append(d['note'])\n","                event.append(d['time'])\n","                event.append(d['channel'])\n","                note_array.append(event)\n","        \n","        # add the note information\n","        track_info['note_data'] = note_array\n","        \n","        # add track to entire midi file array\n","        midi_array.append(track_info)\n","\n","    return midi_array"],"metadata":{"id":"-1KQty6ER2Y2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# parsing an example midi file\n","mid_file   = midi_files[1]  # example file: \"A Sleepin' Bee.mid\"\n","mid        = load_midi(mid_file, quantize=True)\n","midi_array = midi_parser(mid)"],"metadata":{"id":"buvQkHfSOfji"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# assigning plot vectors\n","note_on_values  = [row[1] for row in midi_array[0]['note_data'] if row[0] == 'note_on']\n","note_on_times   = [row[2] for row in midi_array[0]['note_data'] if row[0] == 'note_on']\n","note_off_values = [row[1] for row in midi_array[0]['note_data'] if row[0] == 'note_off']\n","note_off_times  = [row[2] for row in midi_array[0]['note_data'] if row[0] == 'note_off']\n","\n","# plotting midi\n","fig, ax = plt.subplots(figsize=(10, 5))\n","ax.scatter(note_on_times, note_on_values, s=3.5, color='green')\n","ax.scatter(note_off_times, note_off_values, s=3.5, color='red')\n","ax.set(title=f'MIDI Notes for {mid_file}')\n","ax.set(ylabel='MIDI Value (0-127)')\n","ax.set(xlabel='Time (sec)')\n","ax.grid(visible='on', which='both')\n","fig.tight_layout()\n","fig.show()"],"metadata":{"id":"ST10nA8sVEff"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Convert MIDI to Note Name"],"metadata":{"id":"bH6M8WtfR34H"}},{"cell_type":"code","source":["def convert_key_format(midi_array):\n","    \"\"\"\n","    Convert key from mido format to librosa format.\n","    \n","    :param midi_array: (list) parsed MIDI array\n","    :return: (str) converted key in librosa format (e.g. C:maj)\n","    \"\"\"\n","    # a total of 30 applicable music key signatures\n","    # A Am    A#m Ab Abm \n","    # B Bm        Bb Bbm \n","    # C Cm C# C#m Cb \n","    # D Dm    D#m Db \n","    # E Em        Eb Ebm \n","    # F Fm F# F#m \n","    # G Gm    G#m Gb \n","    chord_keys = {'A':'A:maj', 'Am':'A:min',                'A#m':'A#:min', 'Ab':'Ab:maj', 'Abm':'Ab:min',\n","                  'B':'B:maj', 'Bm':'B:min',                                'Bb':'Bb:maj', 'Bbm':'Bb:min',\n","                  'C':'C:maj', 'Cm':'C:min', 'C#':'C#:maj', 'C#m':'C#:min', 'Cb':'Cb:maj',\n","                  'D':'D:maj', 'Dm':'D:min',                'D#m':'D#:min', 'Db':'Db:maj',\n","                  'E':'E:maj', 'Em':'E:min',                                'Eb':'Eb:maj', 'Ebm':'Eb:min',\n","                  'F':'F:maj', 'Fm':'F:min', 'F#':'F#:maj', 'F#m':'F#:min',\n","                  'G':'G:maj', 'Gm':'G:min',                'G#m':'G#:min', 'Gb':'Gb:maj'}\n","    \n","    converted_key_format = 'C:maj'  # default key\n","    for track in midi_array:\n","        if 'key' in track['metadata']:\n","            # find the corresponding librosa key format\n","            converted_key_format = chord_keys[track['metadata']['key']]\n","    return converted_key_format"],"metadata":{"id":"WLBS12Q_eHl5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def convert_notes(arr, key=None):\n","    \"\"\"\n","    Convert MIDI integers to note names.\n","    \n","    :param arr: (list) parsed MIDI array\n","    :param key: (str) predetermined key in librosa format\n","                if not provided, the key is extracted from the MIDI file\n","    :return: (list) MIDI array with note names in provided key\n","    \"\"\"\n","    if key is None:\n","        midi_key = convert_key_format(arr)\n","    else:\n","        midi_key = key\n","    for track in arr:\n","        new_data = []\n","        if len(track['note_data']) > 0:\n","            for note in track['note_data']:\n","                # convert MIDI number to note name\n","                note[1] = librosa.midi_to_note(note[1], key=midi_key)\n","                new_data.append(note)\n","            track['note_data'] = new_data\n","    return arr"],"metadata":{"id":"ALYziEMjR6vq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["note_array = convert_notes(midi_array)"],"metadata":{"id":"OquWSg06R-QH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Chunk the MIDI Data into Beats"],"metadata":{"id":"tbRAefK1SBMA"}},{"cell_type":"code","source":["def process_times(data):\n","    \"\"\"\n","    Convert note data to find the onset and offset times for each note, along with its duration.\n","    \n","    :param data: (list) note data\n","    :return: (list) time data\n","    \"\"\"\n","    # convert data to a pandas dataframe\n","    df = pd.DataFrame(data)\n","    # label the columns\n","    df.columns = ['event', 'note', 'time', 'channel']\n","    # sort the data by note first, then time to get each note on and off in consecutive rows\n","    df.sort_values(['note', 'time'], inplace=True)\n","    \n","    notes    = []\n","    note_on  = []\n","    note_off = []\n","    channel  = []\n","    \n","    # group every two rows together (one note on and one note off)\n","    for i, g in df.groupby(np.arange(len(df)) // 2):\n","        notes   .append(g.iloc[0, 1])\n","        note_on .append(g.iloc[0, 2])\n","        note_off.append(g.iloc[1, 2])\n","        channel .append(g.iloc[0, 3])\n","\n","    # create a new dataframe\n","    df_times = pd.DataFrame({'note': notes, 'time_on': note_on, 'time_off': note_off, 'channel': channel})\n","    # sort by time to reconstruct the note sequence\n","    df_times.sort_values(['time_on', 'time_off'], ignore_index=True, inplace=True)\n","    # compute the duration of each note\n","    df_times['duration'] = df_times['time_off'] - df_times['time_on']\n","    # reorder columns\n","    df_times = df_times[['note', 'time_on', 'time_off', 'duration', 'channel']]\n","    # convert to list\n","    times_list = df_times.values.tolist()\n","    return times_list"],"metadata":{"id":"Am2BQ9t4SEKl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for d in note_array:\n","    if len(d['note_data']) > 0:\n","        d['time_data'] = process_times(d['note_data'])"],"metadata":{"id":"iciWiXyASGKw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_notes_by_beat(data, seconds_per_beat, total_time, keep_embellishments=True, subdivision=4):\n","    \"\"\"\n","    Get the notes which are played during each beat.\n","    \n","    :param data: (list) note data\n","    :param seconds_per_beat: (float) length of a beat in seconds\n","    :param total_time: (float) length of the MIDI file in seconds\n","    :param keep_embellishments: (bool) whether to keep embellishment tones\n","                                (e.g. passing or neighboring tones)\n","    :param subdivision: (int) if keep_embellishments is False, the minimum subdivision\n","                              of the beat for which a note can be included in the final output\n","                              (e.g. if subdivision=2 and the timesignature is 4/4, any note\n","                              less than an eighth note will be dropped)\n","    :return: (list) nested list where each item is a list of notes\n","                    played during beat i\n","    \"\"\"\n","    # get the timestamps of each beat\n","    beat_timestamps = list(np.arange(0, total_time, spb))\n","    \n","    # create an empty nested list where each item represents one beat\n","    notes_by_beat = [[] for i in np.arange(len(beat_timestamps))]\n","    \n","    # convert list to dataframe\n","    df = pd.DataFrame(data, columns=['note', 'time_on', 'time_off', 'duration', 'channel'])\n","    \n","    if not keep_embellishments:\n","        df = df[df['duration'] >= round(seconds_per_beat / subdivision, 6)]\n","    \n","    # compute the number of beats in the duration\n","    df['num_beats'] = np.ceil(df['duration'] / seconds_per_beat)\n","    \n","    # iterate over each note\n","    for idx, row in df.iterrows():\n","        # find which beat the note starts on\n","        beat_start = sum([row['time_on'] > t for t in beat_timestamps]) - 1\n","        \n","        # add the note to the correct beats\n","        i = 0\n","        while i < row['num_beats']:\n","            notes_by_beat[beat_start + i].append(row['note'])\n","            i += 1\n","            \n","    # remove duplicates notes from a beat\n","    for i in range(len(notes_by_beat)):\n","        notes_by_beat[i] = list(set(notes_by_beat[i]))\n","\n","    return notes_by_beat"],"metadata":{"id":"LQm2nLnGSHok"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["spb = 60 / get_bpm(mid)\n","for d in note_array:\n","    if 'time_data' in d.keys():\n","        d['beat_data'] = get_notes_by_beat(d['time_data'], spb, mid.length, keep_embellishments=False)"],"metadata":{"id":"8Ow9lNnqSMvh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["note_array[0]"],"metadata":{"id":"eLRgF3x8UN-4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Map Notes to Chords"],"metadata":{"id":"OuqNBRkPXWsg"}},{"cell_type":"markdown","source":["### Using `music21`'s Magical In-built Chord Detection"],"metadata":{"id":"Gq3-sxQeXeb5"}},{"cell_type":"code","source":["def convert_accidentals(chord_list):\n","    '''\n","    Convert accidentals to music21 format.\n","\n","    :param chord_list: (list of list) chord list of list to be converted\n","    :return: (list) a list of converted accidentals\n","    '''\n","    converted_accidentals = [[note.replace(\"♭\", \"-\").replace(\"♯\", \"#\") for note in chord] for chord in chord_list]\n","    return converted_accidentals"],"metadata":{"id":"VWu9PsPUXnQ-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# returns chord type and root names\n","def chord_id(chord_list):\n","    '''\n","    music21 chord identifier function.\n","\n","    :param chord_list: (list of list) chord list of list to be converted\n","    :return: (list) a list of chord types\n","    :return: (list) a list of root names\n","    '''\n","    chord_types = []    # list of chord types\n","    chord_roots = []    # list of chord roots\n","    for chord_idx in range(len(chord_list)):\n","        chord_type = chord.Chord(chord_list[chord_idx])   # gets the chord object\n","        chord_type.root(chord_type.bass())                # identifies the root of chord\n","        chord_types.append(chord_type.pitchedCommonName)  # identifies the chord type\n","        chord_roots.append(chord_type.root().name)        \n","    return chord_types, chord_roots"],"metadata":{"id":"kIK89VFf_ZGz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Using our own MIDI Chord Templates"],"metadata":{"id":"09Nm4DJHXkxW"}},{"cell_type":"code","source":["# Run the necessary functions to create an array for our chord template\n","chords = '/content/drive/MyDrive/mir_datasets/all_chords.mid'     # Please upload the chords.midi file to the mir_datasets folder in Drive\n","\n","chords_mid = load_midi(chords, quantize = False)\n","\n","chord_array = convert_notes(midi_parser(chords_mid), key = note_array[0]['metadata']['key'] + ':maj')  #gets they key from the current song being analyzed"],"metadata":{"id":"MpPZ-jbRRgOg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for d in chord_array:\n","    if len(d['note_data']) > 0:\n","        d['time_data'] = process_times(d['note_data'])\n","        print(len(d['time_data']))"],"metadata":{"id":"eQNcp5RgRgLp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["spb"],"metadata":{"id":"JCgAtjHtWYni"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["chords_mid.length"],"metadata":{"id":"IDId9Z2cW8Bb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["spb = 60 / get_bpm(chords_mid)\n","for d in chord_array:\n","    if 'time_data' in d.keys():\n","        d['beat_data'] = get_notes_by_beat(d['time_data'], spb, chords_mid.length, keep_embellishments=False)"],"metadata":{"id":"l2o9bxJbRgIh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Create a list including all of the chords in the chord template midi file\n","all_chords = []\n","for i in np.arange(1, len(chord_array)):\n","    all_chords = all_chords + [x for x in chord_array[i]['beat_data'][0::4] if x]"],"metadata":{"id":"kR07TCeySDLq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Remove all octave numbers from list\n","for i in np.arange(len(all_chords)):\n","    for j in np.arange(len(all_chords[i])):\n","        all_chords[i][j] = remove_octave(all_chords[i][j])"],"metadata":{"id":"qRhn8uuKRHvZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["len(all_chords)"],"metadata":{"id":"3q44n5APRHr2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Create lists of keys and chord names\n","keys = ['C', 'C#', 'Db', 'D', 'D#', 'Eb', 'E', 'F', 'F#', 'Gb', 'G', 'G#', 'Ab', 'A', 'A#', 'Bb', 'B', 'Cb']\n","chord_names = ['maj', 'maj7', '6', '6/9', 'maj9', 'maj9(no3)', 'maj9(no5)', '13', '13(no3)', '13(no5)', 'maj13', 'maj13(no11)', 'maj13(no5)', 'maj13(no9)', 'm', 'm7', 'm6', 'm6/9', 'm9', 'm9(no3)', 'm9(no5)', 'm11', 'm11(no3)', 'm11(no9)', 'm13',  'm13(no11)', 'm13(no5_no9_no11)',  'mmaj7', 'mmaj7/9', '7', '7sus', '9', '9sus', '9(no3)', '9(no5)', '11', '11(no3)', '11(no9)', 'dim', 'dim7', 'm7/-5', 'aug', 'aug7', '7/-5', '7/-9', '7/#9', '7#11', '5', 'add9', 'add11', 'sus4', 'sus2']"],"metadata":{"id":"AayFWJCprC7h"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create a dictionary with the chord labels as keys and a list of the notes in the chord as values\n","chord_dict = {}\n","counter = 0\n","for i in keys:\n","  for j in chord_names:\n","    chord_dict[i+j] = all_chords[counter]\n","    counter += 1"],"metadata":{"id":"nHlphnsMrC5B"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["chord_dict"],"metadata":{"id":"yUh5p29prC2U"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Test a chord\n","chord_dict['Bm9(no5)']"],"metadata":{"id":"TxQxTlFcRZXY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Test similarity function\n","calculate_similarity(['B', 'E', 'G♭'], ['B', 'E', 'G♭', 'D'])"],"metadata":{"id":"unOK91DQRZPZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Get rid of the octaves in the note_array\n","for i in np.arange(len(note_array[0]['beat_data'])):\n","    for j in np.arange(len(note_array[0]['beat_data'][i])):\n","        note_array[0]['beat_data'][i][j] = remove_octave(note_array[0]['beat_data'][i][j])"],"metadata":{"id":"gLl4bHLORZHt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["note_array[0]['beat_data']"],"metadata":{"id":"V3T7p6RAZdCR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Function that takes in the beat data and outputs the closest matches in the template\n","\n","def chord_output(beat_data):\n","    song_chords = []\n","    for i in np.arange(len(note_array[0]['beat_data'])):\n","        similarity = []\n","        for j in np.arange(len(chord_dict)):\n","            #chords = list(chord_dict.values()) #or all_chords\n","            similarity.append(calculate_similarity(note_array[0]['beat_data'][i], all_chords[j]))\n","        song_chords.append(all_chords[np.argmax(similarity)])\n","    return song_chords"],"metadata":{"id":"4Poin-WNZe30"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["chord_outputs = chord_output(note_array[0]['beat_data'])"],"metadata":{"id":"2In4ziSTZgwk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["chord_outputs"],"metadata":{"id":"U7CERxjtZguR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Function that labels the chords\n","\n","def label_chords(chords):\n","    labels = []\n","    for k in chords:\n","        labels.append([chord for chord, notes in chord_dict.items() if notes == k])\n","    return labels"],"metadata":{"id":"8mOCWItXZgq8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["label_chords(chord_outputs)"],"metadata":{"id":"v4SPrk3mZgmf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Scratch Work"],"metadata":{"id":"Xt50qt6nq7Zp"}},{"cell_type":"markdown","source":["### Using `music21` to Read MIDI Files (Disregard)"],"metadata":{"id":"gj-XM32GRfGW"}},{"cell_type":"code","source":["test_midi = './test.mid'\n","test_midi0 = converter.parse(test_midi)\n","k = test_midi0.analyze('key')\n","print(k)\n","transposed = test_midi0.transpose(-12)  # do this with all the files if using music21"],"metadata":{"id":"mn0nzatGEYwV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_list = []\n","for n in transposed.recurse().notes:\n","    print(n.offset, ' '.join(p.nameWithOctave for p in n.pitches))\n","    # test_list.append(a)\n","    # print(a)"],"metadata":{"id":"ttWdTD-uIasA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["notes = ['D#3', 'C3', 'G2', 'G#1']\n","\n","_notes = [re.sub('♯', '#', n) for n in notes]\n","\n","_notes\n","\n","c = chord.Chord(_notes)\n","\n","c.commonName\n","\n","c.root()\n","\n","chord_template = load_midi('/Users/richa/Downloads/chords (every key).mid')\n","\n","note_array = convert_notes(midi_parser(chord_template))\n","\n","note_array\n","\n","for d in note_array:\n","    if len(d['note_data']) > 0:\n","        d['time_data'] = process_times(d['note_data'])\n","\n","spb = 60 / get_bpm(chord_template)\n","for d in note_array:\n","    if 'time_data' in d.keys():\n","        d['beat_data'] = get_notes_by_beat(d['time_data'], spb, mid.length)\n","\n","note_array[0]['beat_data']"],"metadata":{"id":"4XRcgI8-q7Hk"},"execution_count":null,"outputs":[]}]}